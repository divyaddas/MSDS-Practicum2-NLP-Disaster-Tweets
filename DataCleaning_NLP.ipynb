{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pyspellchecker","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport string # Library for string operations\n\nimport os\n\n# plotly library\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\nfrom plotly.subplots import make_subplots\n\nimport matplotlib.pyplot as plt #Another plotting libraray\n\n# word cloud library\nfrom wordcloud import WordCloud\n\n#Regex library\nimport re\n\n#Spell Checker\nfrom spellchecker import SpellChecker \nspell = SpellChecker()","execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'spellchecker'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-cc8d753a0d56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#Spell Checker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspellchecker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpellChecker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mspell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpellChecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spellchecker'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"TrainDataSet= pd.read_csv('../input/nlp-getting-started/train.csv')\nTestDataSet=pd.read_csv('../input/nlp-getting-started/test.csv')\nTrainDataSet.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TrainDataSet[TrainDataSet[\"target\"] == 0][\"text\"].values[0:120]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(min_df=0,stop_words=\"english\", max_features=200)\ncounts = cv.fit_transform(TrainDataSet[\"text\"][0:500]).toarray().ravel()\nwords = np.array(cv.get_feature_names()) \n#counts = counts / float(counts.max())\n#print(words)\nprint(counts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning\n\nWe need to clean the data to avoid errors and incorrect results\n\n* **Remove URL from the tweet**\nURL'S some error during processing so we are using regex library to remove the urls"},{"metadata":{"trusted":true},"cell_type":"code","source":"TrainDataSet['text'] = TrainDataSet['text'].apply(lambda x: re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', str(x)))\nTrainDataSet.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TestDataSet['text'] = TestDataSet['text'].apply(lambda x: re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', str(x)))\nTestDataSet.tail(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Remove Emoji from the tweet**\nwe need to remove emoji from the tweet since people are using lot of emojies in there tweet to express emotions. We need to create function so we can specify different emoji patterns with range of unicode characters, the list is not complete but good for now."},{"metadata":{"trusted":true},"cell_type":"code","source":"def EmojiCleanser(text):\n    regrex_pattern = re.compile(pattern = \"[\"\n        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           \"]+\", flags = re.UNICODE)\n    return regrex_pattern.sub(r'',text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TestDataSet['text'] = TestDataSet['text'].apply(lambda x: EmojiCleanser(str(x)))\nTrainDataSet['text'] = TrainDataSet['text'].apply(lambda x: EmojiCleanser(str(x)))\nTrainDataSet.tail(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Remove HTML Tags from Tweet**\nwe need to remove html tags so we can avoid creating unncessary tokens. we can use a regex expression to remove those tags."},{"metadata":{"trusted":true},"cell_type":"code","source":"TestDataSet['text'] = TestDataSet['text'].apply(lambda x: re.sub(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});', '', str(x)))\nTrainDataSet['text'] = TrainDataSet['text'].apply(lambda x: re.sub(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});', '', str(x)))\nTrainDataSet.tail(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Remove Punctuations from the Tweet**\nwe need to remove the puntuations from tweet so we are using string libraray to remove the punctuations"},{"metadata":{"trusted":true},"cell_type":"code","source":"TestDataSet['text'] = TestDataSet['text'].apply(lambda x: str(x).translate(str.maketrans('','',string.punctuation)))\nTrainDataSet['text'] = TrainDataSet['text'].apply(lambda x: str(x).translate(str.maketrans('','',string.punctuation)))\nTrainDataSet.tail(3)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*** Spell correction in tweets**\nWe need to correct the spelling in tweets so we will get more accurate tokens. We can use SpellChecker in pyspellchecker library."},{"metadata":{"trusted":true},"cell_type":"code","source":"#TestDataSet['text'] = TestDataSet['text'].apply(lambda x: \" \".join([spell.correction(i) for i in str(x).split()]))\n#TrainDataSet['text'] = TrainDataSet['text'].apply(lambda x: \" \".join([spell.correction(i) for i in str(x).split()]))\n#TrainDataSet.tail(3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filling missing values \n#TrainDataSet[['keyword']] = TrainDataSet[['keyword']].fillna('Not Identified')\n#TrainDataSet[['location']] = TrainDataSet[['location']].fillna('Not Identified')\n\nTrainDataSet = TrainDataSet[TrainDataSet.keyword.notnull()]\nTrainDataSet = TrainDataSet[TrainDataSet.location.notnull()]\n\n\nGrouped_Disaster = TrainDataSet.groupby(['keyword'])['id'].count().reset_index()\nGrouped_Location = TrainDataSet.groupby(['location'])['id'].count().reset_index()\n\nGrouped_Disaster = Grouped_Disaster.query('keyword !=\"Not Identified\"' )\nGrouped_Location = Grouped_Location.query('location !=\"Not Location\"' )\n\nGroup_Disaster_filter = Grouped_Disaster.sort_values('id',ascending=False)[:20][::-1]\nGrouped_Location_filter = Grouped_Location.sort_values('id',ascending=False)[:20][::-1]\n\nfig = make_subplots(\n    rows=1, cols=2,\n    specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}]],\n    subplot_titles=(\"Top 20 Disaster by Tweets\",\"Top 20 Tweet Location\")\n)\n\nfig.add_trace(go.Bar(name='id',text='id', x=Group_Disaster_filter['keyword'], y=Group_Disaster_filter['id']),\n              row=1, col=1)\n\n\nfig.add_trace(go.Bar(name='id',text='id', x=Grouped_Location_filter['location'], y=Grouped_Location_filter['id']),\n              row=1, col=2)\n\nfig.update_layout(height=700,title_text=\"Tweets Breakdown\", showlegend=False)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\ntext = TrainDataSet.text.values\nwordcloud = WordCloud(\n    width = 3000,\n    height = 2000,\n    background_color = 'black',\n    stopwords = STOPWORDS).generate(str(text))\nfig = plt.figure(\n    figsize = (40, 30),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TrainDataSet.tail(20)\nTrainDataSet[TrainDataSet[\"target\"] == 0][\"text\"].values[0:120]\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}